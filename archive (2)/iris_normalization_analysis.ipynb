{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Iris Dataset Classification with Feature Normalization\n",
        "\n",
        "This notebook demonstrates different feature normalization techniques on the famous Iris dataset for classification tasks.\n",
        "\n",
        "## Dataset Overview\n",
        "- **Features**: 4 numerical features (sepal length, sepal width, petal length, petal width)\n",
        "- **Target**: 3 species classes (Iris-setosa, Iris-versicolor, Iris-virginica)\n",
        "- **Samples**: 150 (50 per class)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for better plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load and Explore the Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the Iris dataset\n",
        "df = pd.read_csv('Iris.csv')\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nColumn information:\")\n",
        "df.info()\n",
        "\n",
        "print(f\"\\nFirst 5 rows:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Feature Normalization Demonstration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate features and target\n",
        "feature_columns = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
        "X = df[feature_columns].copy()\n",
        "y = df['Species'].copy()\n",
        "\n",
        "print(\"Original feature statistics:\")\n",
        "print(X.describe())\n",
        "\n",
        "# Apply different normalization techniques\n",
        "standard_scaler = StandardScaler()\n",
        "minmax_scaler = MinMaxScaler()\n",
        "robust_scaler = RobustScaler()\n",
        "\n",
        "X_standard = pd.DataFrame(standard_scaler.fit_transform(X), columns=feature_columns)\n",
        "X_minmax = pd.DataFrame(minmax_scaler.fit_transform(X), columns=feature_columns)\n",
        "X_robust = pd.DataFrame(robust_scaler.fit_transform(X), columns=feature_columns)\n",
        "\n",
        "# Visualize the differences\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "X.boxplot(ax=axes[0, 0])\n",
        "axes[0, 0].set_title('Original Data')\n",
        "axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "X_standard.boxplot(ax=axes[0, 1])\n",
        "axes[0, 1].set_title('StandardScaler (mean=0, std=1)')\n",
        "axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "X_minmax.boxplot(ax=axes[1, 0])\n",
        "axes[1, 0].set_title('MinMaxScaler (range 0-1)')\n",
        "axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "X_robust.boxplot(ax=axes[1, 1])\n",
        "axes[1, 1].set_title('RobustScaler (median/IQR)')\n",
        "axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n=== NORMALIZATION SUMMARY ===\")\n",
        "print(\"1. StandardScaler: Centers data around mean=0, std=1\")\n",
        "print(\"2. MinMaxScaler: Scales features to range [0,1]\") \n",
        "print(\"3. RobustScaler: Uses median and IQR, robust to outliers\")\n",
        "print(\"\\nFor the Iris dataset, all methods work well due to clean, well-distributed data.\")\n",
        "print(\"StandardScaler is typically recommended for neural networks and SVM.\")\n",
        "print(\"MinMaxScaler is good for distance-based algorithms like KNN.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
